{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLM-RoBERTa\n",
    "*Time for run all (GPU): ~4 hours*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General Settings and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torchtext\n",
    "import torchtext.transforms as T\n",
    "import torchtext.functional as F\n",
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasettt.csv\")\n",
    "# columns_to_remove = ['Unnamed: 2','Unnamed: 3','Unnamed: 4']\n",
    "# df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love you sir!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you very much, u really got me in the fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Another great explanation by Abdul sir. Thank ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had no idea what was going on in the first o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thankkk youuuuu soooo sooo much sir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>Practise, practise, practise, I couldn't agree...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>Need a small hep from you. Have my GRE in 3 da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>I failed at last question ðŸ˜¢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>Thatâ€™s true tht happen to me the first thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>the video is not working after 31 seconds :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "0                                        Love you sir!!      2\n",
       "1     Thank you very much, u really got me in the fi...      2\n",
       "2     Another great explanation by Abdul sir. Thank ...      2\n",
       "3     I had no idea what was going on in the first o...      2\n",
       "4                   Thankkk youuuuu soooo sooo much sir      2\n",
       "...                                                 ...    ...\n",
       "2522  Practise, practise, practise, I couldn't agree...      0\n",
       "2523  Need a small hep from you. Have my GRE in 3 da...      0\n",
       "2524                     I failed at last question ðŸ˜¢      0\n",
       "2525  Thatâ€™s true tht happen to me the first thing...      0\n",
       "2526       the video is not working after 31 seconds :(      0\n",
       "\n",
       "[2527 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love you sir!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank you very much, u really got me in the fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another great explanation by abdul sir. thank ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i had no idea what was going on in the first o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankkk youuuuu soooo sooo much sir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>practise, practise, practise, i couldn't agree...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>need a small hep from you. have my gre in 3 da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>i failed at last question ðÿ˜¢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>thatâ€™s true tht happen to me the first thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>the video is not working after 31 seconds :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "0                                        love you sir!!      2\n",
       "1     thank you very much, u really got me in the fi...      2\n",
       "2     another great explanation by abdul sir. thank ...      2\n",
       "3     i had no idea what was going on in the first o...      2\n",
       "4                   thankkk youuuuu soooo sooo much sir      2\n",
       "...                                                 ...    ...\n",
       "2522  practise, practise, practise, i couldn't agree...      0\n",
       "2523  need a small hep from you. have my gre in 3 da...      0\n",
       "2524                     i failed at last question ðÿ˜¢      0\n",
       "2525  thatâ€™s true tht happen to me the first thing...      0\n",
       "2526       the video is not working after 31 seconds :(      0\n",
       "\n",
       "[2527 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercasing\n",
    "df['Comment'] = df['Comment'].str.lower()\n",
    "\n",
    "# removing urls\n",
    "df['Comment'] = df['Comment'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "\n",
    "# removing commas \"\\n\"\n",
    "df['Comment'] = df['Comment'].replace('\\n','', regex=True)\n",
    "\n",
    "# removing all the punctuations\n",
    "df['Comment'] = df['Comment'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# removing integers\n",
    "#df['Comment'] = df['Comment'].replace('\\d','', regex=True)\n",
    "\n",
    "# removing emojis\n",
    "#df['Comment'] = df['Comment'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "def typo_corrector(text):\n",
    "    return spell(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(typo_corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "import nltk\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(stem_text)\n",
    "\n",
    "\n",
    "# lemmatizing\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# These are the words that should not be removed from their category\n",
    "negative_words = ['no','not']\n",
    "neutral_words = ['how','what','which','who','whom','why','do','does','is','are','was','were','will','am',\n",
    "                      'are','could','would','should','can','did','does','do','had','have']\n",
    "\n",
    "for_negative_category = stop.copy()\n",
    "for word in negative_words:\n",
    "    if word in for_negative_category:\n",
    "        for_negative_category.remove(word)\n",
    "    \n",
    "for_neutral_category = stop.copy()\n",
    "for word in neutral_words:\n",
    "    if word in for_neutral_category:\n",
    "        for_neutral_category.remove(word)\n",
    "\n",
    "# For negative category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"negative\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in for_negative_category])\n",
    "\n",
    "# For neutral category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"neutral\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in for_neutral_category])\n",
    "        \n",
    "# For positive category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"positive\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>i'm getting a 'nameerror: name 'shuffle' is no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>wonderful video ðÿ'ðÿ'ðÿ'</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>best lecture i have ever seen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>that is very very very helpful...thank you sir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>i have never learned programming formally and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>i bought both of your courses on dmy. you are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>hi i am using windows 10, 64 bit os &amp; i am get...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>hello from india ðÿ‡®ðÿ‡³. loved your channel!...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>i have run my first program success</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>volume and size high quality1or 2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "2266  i'm getting a 'nameerror: name 'shuffle' is no...      0\n",
       "983                        wonderful video ðÿ'ðÿ'ðÿ'      2\n",
       "194                       best lecture i have ever seen      2\n",
       "189      that is very very very helpful...thank you sir      2\n",
       "715   i have never learned programming formally and ...      2\n",
       "...                                                 ...    ...\n",
       "1033  i bought both of your courses on dmy. you are ...      1\n",
       "1731  hi i am using windows 10, 64 bit os & i am get...      1\n",
       "763   hello from india ðÿ‡®ðÿ‡³. loved your channel!...      2\n",
       "835                 i have run my first program success      2\n",
       "1653                  volume and size high quality1or 2      1\n",
       "\n",
       "[2021 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>thanks alice. really nice tutorial.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>hey i installed the jk file on my windows 10 a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>can anyone tell me what was the purpose of thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>very helpful video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>why would we learn this? anybody still learn e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>hi i have problem on w7 it doesnt show this hu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>thank you for creating a free structured progr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>thanks for this wonderful presentation have ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>my system is 32 bits, can i still use 64 bits ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>i thought python programming is difficult, but...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "478                 thanks alice. really nice tutorial.      2\n",
       "1830  hey i installed the jk file on my windows 10 a...      1\n",
       "1804  can anyone tell me what was the purpose of thi...      1\n",
       "997                                  very helpful video      2\n",
       "1821  why would we learn this? anybody still learn e...      1\n",
       "...                                                 ...    ...\n",
       "1850  hi i have problem on w7 it doesnt show this hu...      1\n",
       "700   thank you for creating a free structured progr...      2\n",
       "1902  thanks for this wonderful presentation have ca...      1\n",
       "1873  my system is 32 bits, can i still use 64 bits ...      1\n",
       "921   i thought python programming is difficult, but...      2\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "train_df['Label'] = label_encoder.fit_transform(train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Label'] = label_encoder.transform(test_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadTransform(torch.nn.Module):\n",
    "    \"\"\"Pad tensor to a fixed length with given padding value.\n",
    "    :param max_length: Maximum length to pad to\n",
    "    :type max_length: int\n",
    "    :param pad_value: Value to pad the tensor with\n",
    "    :type pad_value: bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_length: int, pad_value: int) -> None:\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.pad_value = float(pad_value)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param x: The tensor to pad\n",
    "        :type x: Tensor\n",
    "        :return: Tensor padded up to max_length with pad_value\n",
    "        :rtype: Tensor\n",
    "        \"\"\"\n",
    "        max_encoded_length = x.size(-1)\n",
    "        if max_encoded_length < self.max_length:\n",
    "            pad_amount = self.max_length - max_encoded_length\n",
    "            x = torch.nn.functional.pad(x, (0, pad_amount), value=self.pad_value)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = torchtext.models.XLMR_LARGE_ENCODER.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(text_transform(self.df.iloc[idx, 0])),\n",
    "            torch.tensor(self.df.iloc[idx, 1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_BATCH_SIZE = 16\n",
    "K = 2\n",
    "LARGE_BATCH_SIZE = K * SMALL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_collate_fn(batch):\n",
    "    inp_list = list()\n",
    "    tar_list = list()\n",
    "    \n",
    "    for sample in batch:\n",
    "        inp_list.append(sample[0].tolist())\n",
    "        tar_list.append(sample[1])\n",
    "        \n",
    "    padded_tensor = F.to_tensor(inp_list, padding_value=padding_idx)\n",
    "    target_tensor = torch.stack(tar_list).type(torch.LongTensor)\n",
    "    \n",
    "    return padded_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=SMALL_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=batch_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=SMALL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=batch_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "input_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "model = XLMR_BASE_ENCODER.get_model(head=classifier_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.2e-5 \n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "criteria = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input, target, small_batch_no):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    if (small_batch_no + 1) % K == 0 or (small_batch_no + 1) == len(train_dataloader):\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    \n",
    "    return loss.item() / input.size(dim=0)\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            input = batch[0].clone().detach().to(DEVICE)\n",
    "            output = model(input)\n",
    "            target = batch[1].clone().detach().to(DEVICE)\n",
    "            \n",
    "            if i == 0:\n",
    "                class_output = torch.argmax(output, dim=1)\n",
    "                class_target = target\n",
    "            else:\n",
    "                class_output = torch.cat([class_output, torch.argmax(output, dim=1)])\n",
    "                class_target = torch.cat([class_target, target])\n",
    "            \n",
    "            loss = criteria(output, target).item()\n",
    "            total_loss += loss\n",
    "            counter += input.size(dim=0)\n",
    "            \n",
    "            \n",
    "        confusion_matrix = metrics.confusion_matrix(\n",
    "            class_target.cpu().numpy().flatten(),\n",
    "            class_output.cpu().numpy().flatten(),\n",
    "            labels=[0, 1, 2]\n",
    "        ) \n",
    "        classification_report = metrics.classification_report(\n",
    "            class_target.cpu().numpy().flatten(),\n",
    "            class_output.cpu().numpy().flatten(),\n",
    "            labels=[0, 1, 2],\n",
    "            output_dict=True\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        total_loss,\n",
    "        counter,\n",
    "        confusion_matrix,\n",
    "        classification_report\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(epoch, **kwargs):\n",
    "    with open(f'log_{epoch}.pkl', 'wb') as f:\n",
    "        pickle.dump(kwargs, f)\n",
    "\n",
    "def save_model(message):\n",
    "    torch.save(model.state_dict(), f'model_{message}.pth')\n",
    "    print('Model saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = float('-inf')\n",
    "max_macro_f1 = float('-inf')\n",
    "max_weighted_f1 = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/transformer.py:296: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:179.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Mean of avg_training_losses=0.06632268078566536\n",
      "total_loss=29.28060233592987\n",
      "counter=506\n",
      "loss=total_loss/counter=0.057866803035434525\n",
      "confusion_matrix=\n",
      "[[  0  50  47]\n",
      " [  0 141  61]\n",
      " [  0   3 204]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 97},\n",
      " '1': {'f1-score': 0.712121212121212,\n",
      "       'precision': 0.7268041237113402,\n",
      "       'recall': 0.698019801980198,\n",
      "       'support': 202},\n",
      " '2': {'f1-score': 0.7861271676300579,\n",
      "       'precision': 0.6538461538461539,\n",
      "       'recall': 0.9855072463768116,\n",
      "       'support': 207},\n",
      " 'accuracy': 0.6818181818181818,\n",
      " 'macro avg': {'f1-score': 0.4994161265837566,\n",
      "               'precision': 0.4602167591858313,\n",
      "               'recall': 0.5611756827856699,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.6058830208456656,\n",
      "                  'precision': 0.5576296182526573,\n",
      "                  'recall': 0.6818181818181818,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    avg_training_losses = list()\n",
    "    \n",
    "    for small_batch_no, small_batch in enumerate(train_dataloader):\n",
    "        input = small_batch[0].clone().detach().to(DEVICE)\n",
    "        target = small_batch[1].clone().detach().to(DEVICE)\n",
    "        avg_training_losses.append(\n",
    "            train_step(input, target, small_batch_no)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    total_loss, counter, confusion_matrix, classification_report = evaluate()\n",
    "    print(f'EPOCH {epoch}')\n",
    "    print(f'Mean of avg_training_losses={np.mean(avg_training_losses)}')\n",
    "    print(f'total_loss={total_loss}')\n",
    "    print(f'counter={counter}')\n",
    "    print(f'loss=total_loss/counter={total_loss/counter}')\n",
    "    print(f'confusion_matrix=\\n{confusion_matrix}')\n",
    "    print('classification_report=')\n",
    "    pprint.pprint(classification_report)\n",
    "    \n",
    "    save_log(\n",
    "        epoch,\n",
    "        avg_training_losses=avg_training_losses,\n",
    "        total_loss=total_loss,\n",
    "        counter=counter,\n",
    "        loss=total_loss/counter,\n",
    "        confusion_matrix=confusion_matrix,\n",
    "        classification_report=classification_report\n",
    "    )\n",
    "    \n",
    "    if classification_report['accuracy'] > max_accuracy:\n",
    "        print(f'New max_accuracy')\n",
    "        max_accuracy = classification_report['accuracy']\n",
    "        max_accuracy_index = epoch\n",
    "        save_model('max_accuracy')\n",
    "        \n",
    "    elif classification_report['macro avg']['f1-score'] > max_macro_f1:\n",
    "        print(f'New max_macro_f1')\n",
    "        max_macro_f1 = classification_report['macro avg']['f1-score']\n",
    "        max_macro_f1_index = epoch\n",
    "        save_model('max_macro_f1')\n",
    "    \n",
    "    elif classification_report['weighted avg']['f1-score'] > max_weighted_f1:\n",
    "        print(f'New max_weighted_f1')\n",
    "        max_weighted_f1 = classification_report['weighted avg']['f1-score']\n",
    "        max_weighted_f1_index = epoch\n",
    "        save_model('max_weighted_f1')\n",
    "    \n",
    "    elif epoch == num_epochs - 1:\n",
    "        save_model(f'{epoch}_last')\n",
    "    \n",
    "    elif epoch % 40 == 0:\n",
    "        save_model(f'{epoch}_checkpoint')\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "save_log(\n",
    "    'post_train_info',\n",
    "    max_accuracy=max_accuracy,\n",
    "    max_accuracy_index=max_accuracy_index,\n",
    "    max_macro_f1=max_macro_f1,\n",
    "    max_macro_f1_index=max_macro_f1_index,\n",
    "    max_weighted_f1=max_weighted_f1,\n",
    "    max_weighted_f1_index=max_weighted_f1_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Maximum recorded accuracy = 75.3%*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    num_classes = 3\n",
    "    input_dim = 768\n",
    "\n",
    "    classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "    model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\n",
    "    \n",
    "    DEMO_MODEL_PATH = 'model_max_weighted_f1.pth'\n",
    "    model.load_state_dict(torch.load(DEMO_MODEL_PATH))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    print(f'Loaded model to [{DEVICE}] in [{DEMO_MODEL_PATH}]')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_transform():\n",
    "    text_transform = torchtext.models.XLMR_LARGE_ENCODER.transform()\n",
    "    return text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model, text_transform, label_map):\n",
    "    transformed_text = text_transform(sentence)\n",
    "    out = model(torch.tensor([transformed_text]).to(DEVICE))\n",
    "    return label_map[torch.argmax(out).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'negative',\n",
    "    1: 'neutral',\n",
    "    2: 'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model()\n",
    "text_transform = prepare_text_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'dumb ass'\n",
    "predict(sample_text, model, text_transform, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
