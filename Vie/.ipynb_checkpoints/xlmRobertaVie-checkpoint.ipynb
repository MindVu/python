{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XLM-RoBERTa\n",
    "*Time for run all (GPU): ~4 hours*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. General Settings and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vncorenlp in /opt/homebrew/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from vncorenlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->vncorenlp) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->vncorenlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->vncorenlp) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->vncorenlp) (2023.5.7)\n",
      "--2023-06-09 14:25:47--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 27412575 (26M) [application/octet-stream]\n",
      "Saving to: ‘VnCoreNLP-1.1.1.jar’\n",
      "\n",
      "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   643KB/s    in 47s     \n",
      "\n",
      "2023-06-09 14:26:37 (569 KB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n",
      "\n",
      "--2023-06-09 14:26:37--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 526544 (514K) [application/octet-stream]\n",
      "Saving to: ‘vi-vocab’\n",
      "\n",
      "vi-vocab            100%[===================>] 514.20K   495KB/s    in 1.0s    \n",
      "\n",
      "2023-06-09 14:26:39 (495 KB/s) - ‘vi-vocab’ saved [526544/526544]\n",
      "\n",
      "--2023-06-09 14:26:39--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 128508 (125K) [text/plain]\n",
      "Saving to: ‘wordsegmenter.rdr’\n",
      "\n",
      "wordsegmenter.rdr   100%[===================>] 125.50K   327KB/s    in 0.4s    \n",
      "\n",
      "2023-06-09 14:26:40 (327 KB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Thư viện vncorenlp và wordsegmenter dùng để Word Segmentation cho tiếng Việt\n",
    "\n",
    "# # Install the vncorenlp python wrapper\n",
    "# !pip install vncorenlp\n",
    "\n",
    "# # Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n",
    "# !mkdir -p vncorenlp/models/wordsegmenter\n",
    "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
    "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
    "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
    "# !mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
    "# !mv vi-vocab vncorenlp/models/wordsegmenter/\n",
    "# !mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ông', 'Nguyễn_Khắc_Chúc', 'đang', 'làm_việc', 'tại', 'Đại_học', 'Quốc_gia', 'Hà_Nội', '.'], ['Bà', 'Lan', ',', 'vợ', 'ông', 'Chúc', ',', 'cũng', 'làm_việc', 'tại', 'đây', '.']]\n"
     ]
    }
   ],
   "source": [
    "# rdrsegmenter = VnCoreNLP(\"./vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
    "# text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n",
    "# output = rdrsegmenter.tokenize(text)\n",
    "# print(output)\n",
    "# # ['Ông Nguyễn_Khắc_Chúc đang làm_việc tại Đại_học Quốc_gia Hà_Nội .', 'Bà Lan , vợ ông Chúc , cũng làm_việc tại đây .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torchtext\n",
    "import torchtext.transforms as T\n",
    "import torchtext.functional as F\n",
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from vncorenlp import VnCoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasetVie.csv\")\n",
    "# columns_to_remove = ['Unnamed: 2','Unnamed: 3','Unnamed: 4']\n",
    "# df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chúc mừng các cô gái vàng của đội tuyển bóng đ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hay</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đội tuyển nữ Việt Nam thật là tuyệt vời</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Các gái cam biết thế nào là đội dự wc chưa</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanh nhã xinh</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>Đó mọi người thấy chưa ghê quá, ai thấy t nói ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>Lam vay moi giau cat nha lau</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>Cho di tù</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>từ bỏ nóm này nha mọi người</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>Ghê quá</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "0     Chúc mừng các cô gái vàng của đội tuyển bóng đ...    2.0\n",
       "1                                                   Hay    2.0\n",
       "2       Đội tuyển nữ Việt Nam thật là tuyệt vời    2.0\n",
       "3            Các gái cam biết thế nào là đội dự wc chưa    2.0\n",
       "4                                        Thanh nhã xinh    2.0\n",
       "...                                                 ...    ...\n",
       "2264  Đó mọi người thấy chưa ghê quá, ai thấy t nói ...    0.0\n",
       "2265                       Lam vay moi giau cat nha lau    1.0\n",
       "2266                                          Cho di tù    0.0\n",
       "2267                        từ bỏ nóm này nha mọi người    0.0\n",
       "2268                                            Ghê quá    0.0\n",
       "\n",
       "[2269 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love you sir!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank you very much, u really got me in the fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>another great explanation by abdul sir. thank ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i had no idea what was going on in the first o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankkk youuuuu soooo sooo much sir</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>practise, practise, practise, i couldn't agree...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>need a small hep from you. have my gre in 3 da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>i failed at last question ðÿ˜¢</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>thatâ€™s true tht happen to me the first thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>the video is not working after 31 seconds :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "0                                        love you sir!!      2\n",
       "1     thank you very much, u really got me in the fi...      2\n",
       "2     another great explanation by abdul sir. thank ...      2\n",
       "3     i had no idea what was going on in the first o...      2\n",
       "4                   thankkk youuuuu soooo sooo much sir      2\n",
       "...                                                 ...    ...\n",
       "2522  practise, practise, practise, i couldn't agree...      0\n",
       "2523  need a small hep from you. have my gre in 3 da...      0\n",
       "2524                     i failed at last question ðÿ˜¢      0\n",
       "2525  thatâ€™s true tht happen to me the first thing...      0\n",
       "2526       the video is not working after 31 seconds :(      0\n",
       "\n",
       "[2527 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercasing\n",
    "df['Comment'] = df['Comment'].str.lower()\n",
    "\n",
    "# removing urls\n",
    "df['Comment'] = df['Comment'].str.replace('http\\S+|www.\\S+', '', case=False)\n",
    "\n",
    "# removing commas \"\\n\"\n",
    "df['Comment'] = df['Comment'].replace('\\n','', regex=True)\n",
    "\n",
    "# removing all the punctuations\n",
    "df['Comment'] = df['Comment'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# removing integers\n",
    "#df['Comment'] = df['Comment'].replace('\\d','', regex=True)\n",
    "\n",
    "# removing emojis\n",
    "#df['Comment'] = df['Comment'].str.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "def typo_corrector(text):\n",
    "    return spell(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(typo_corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "import nltk\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(stem_text)\n",
    "\n",
    "\n",
    "# lemmatizing\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "\n",
    "df['Comment'] = df['Comment'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# These are the words that should not be removed from their category\n",
    "negative_words = ['no','not']\n",
    "neutral_words = ['how','what','which','who','whom','why','do','does','is','are','was','were','will','am',\n",
    "                      'are','could','would','should','can','did','does','do','had','have']\n",
    "\n",
    "for_negative_category = stop.copy()\n",
    "for word in negative_words:\n",
    "    if word in for_negative_category:\n",
    "        for_negative_category.remove(word)\n",
    "    \n",
    "for_neutral_category = stop.copy()\n",
    "for word in neutral_words:\n",
    "    if word in for_neutral_category:\n",
    "        for_neutral_category.remove(word)\n",
    "\n",
    "# For negative category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"negative\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in for_negative_category])\n",
    "\n",
    "# For neutral category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"neutral\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in for_neutral_category])\n",
    "        \n",
    "# For positive category\n",
    "for i in range(len(df)):\n",
    "    if df[\"Label\"][i] == \"positive\":\n",
    "        df[\"Comment\"][i] = ' '.join([word for word in df[\"Comment\"][i].split() if word not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>outstanding love from bd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>sir plz discuss the topic bresenham's circle a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ðÿ™</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>how much do they get paid to do this? i feel s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sir,thank u very much.excellent explained.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>in windows 10 just press new and insert it the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>thank u sir for ur effort in providing such a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>thanks for the sharing. isn't the b-tree order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>what was that?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>good brother .very helpful ,love you and love ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "157                            outstanding love from bd      2\n",
       "1173  sir plz discuss the topic bresenham's circle a...      1\n",
       "836                                                ðÿ™      2\n",
       "2073  how much do they get paid to do this? i feel s...      0\n",
       "135          sir,thank u very much.excellent explained.      2\n",
       "...                                                 ...    ...\n",
       "1638  in windows 10 just press new and insert it the...      1\n",
       "1095  thank u sir for ur effort in providing such a ...      1\n",
       "1130  thanks for the sharing. isn't the b-tree order...      1\n",
       "1294                                     what was that?      1\n",
       "860   good brother .very helpful ,love you and love ...      2\n",
       "\n",
       "[2021 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>out of curiosity , what should i learn to get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>love from bangladesh</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>best lecture i have ever seen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>sir, when will u come with machine learning al...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>please make medio on bresenhem circle drawing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>sir why an application or software is dependab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>another epic statement at 38:49 \"so only your ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>it is best lecture. it help me understood lots...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>can you please upload a video of tripartite gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>sir..pls up more videos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Label\n",
       "1752  out of curiosity , what should i learn to get ...      1\n",
       "748                                love from bangladesh      2\n",
       "194                       best lecture i have ever seen      2\n",
       "1099  sir, when will u come with machine learning al...      1\n",
       "1178  please make medio on bresenhem circle drawing ...      1\n",
       "...                                                 ...    ...\n",
       "1546  sir why an application or software is dependab...      1\n",
       "76    another epic statement at 38:49 \"so only your ...      2\n",
       "432   it is best lecture. it help me understood lots...      2\n",
       "1124  can you please upload a video of tripartite gr...      1\n",
       "1387                         sir..pls up more videos...      1\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "train_df['Label'] = label_encoder.fit_transform(train_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Label'] = label_encoder.transform(test_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadTransform(torch.nn.Module):\n",
    "    \"\"\"Pad tensor to a fixed length with given padding value.\n",
    "    :param max_length: Maximum length to pad to\n",
    "    :type max_length: int\n",
    "    :param pad_value: Value to pad the tensor with\n",
    "    :type pad_value: bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_length: int, pad_value: int) -> None:\n",
    "        super().__init__()\n",
    "        self.max_length = max_length\n",
    "        self.pad_value = float(pad_value)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        :param x: The tensor to pad\n",
    "        :type x: Tensor\n",
    "        :return: Tensor padded up to max_length with pad_value\n",
    "        :rtype: Tensor\n",
    "        \"\"\"\n",
    "        max_encoded_length = x.size(-1)\n",
    "        if max_encoded_length < self.max_length:\n",
    "            pad_amount = self.max_length - max_encoded_length\n",
    "            x = torch.nn.functional.pad(x, (0, pad_amount), value=self.pad_value)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = torchtext.models.XLMR_LARGE_ENCODER.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(text_transform(self.df.iloc[idx, 0])),\n",
    "            torch.tensor(self.df.iloc[idx, 1])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_BATCH_SIZE = 16\n",
    "K = 2\n",
    "LARGE_BATCH_SIZE = K * SMALL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_collate_fn(batch):\n",
    "    inp_list = list()\n",
    "    tar_list = list()\n",
    "    \n",
    "    for sample in batch:\n",
    "        inp_list.append(sample[0].tolist())\n",
    "        tar_list.append(sample[1])\n",
    "        \n",
    "    padded_tensor = F.to_tensor(inp_list, padding_value=padding_idx)\n",
    "    target_tensor = torch.stack(tar_list).type(torch.LongTensor)\n",
    "    \n",
    "    return padded_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=SMALL_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=batch_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=SMALL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=batch_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "input_dim = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "model = XLMR_BASE_ENCODER.get_model(head=classifier_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.2e-5 \n",
    "optim = AdamW(model.parameters(), lr=learning_rate)\n",
    "criteria = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(input, target, small_batch_no):\n",
    "    output = model(input)\n",
    "    loss = criteria(output, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    if (small_batch_no + 1) % K == 0 or (small_batch_no + 1) == len(train_dataloader):\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    \n",
    "    return loss.item() / input.size(dim=0)\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    counter = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            input = batch[0].clone().detach().to(DEVICE)\n",
    "            output = model(input)\n",
    "            target = batch[1].clone().detach().to(DEVICE)\n",
    "            \n",
    "            if i == 0:\n",
    "                class_output = torch.argmax(output, dim=1)\n",
    "                class_target = target\n",
    "            else:\n",
    "                class_output = torch.cat([class_output, torch.argmax(output, dim=1)])\n",
    "                class_target = torch.cat([class_target, target])\n",
    "            \n",
    "            loss = criteria(output, target).item()\n",
    "            total_loss += loss\n",
    "            counter += input.size(dim=0)\n",
    "            \n",
    "            \n",
    "        confusion_matrix = metrics.confusion_matrix(\n",
    "            class_target.cpu().numpy().flatten(),\n",
    "            class_output.cpu().numpy().flatten(),\n",
    "            labels=[0, 1, 2]\n",
    "        ) \n",
    "        classification_report = metrics.classification_report(\n",
    "            class_target.cpu().numpy().flatten(),\n",
    "            class_output.cpu().numpy().flatten(),\n",
    "            labels=[0, 1, 2],\n",
    "            output_dict=True\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        total_loss,\n",
    "        counter,\n",
    "        confusion_matrix,\n",
    "        classification_report\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(epoch, **kwargs):\n",
    "    with open(f'log_{epoch}.pkl', 'wb') as f:\n",
    "        pickle.dump(kwargs, f)\n",
    "\n",
    "def save_model(message):\n",
    "    torch.save(model.state_dict(), f'model_{message}.pth')\n",
    "    print('Model saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = float('-inf')\n",
    "max_macro_f1 = float('-inf')\n",
    "max_weighted_f1 = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/transformer.py:296: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:179.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Mean of avg_training_losses=0.06568038032984169\n",
      "total_loss=30.7760568857193\n",
      "counter=506\n",
      "loss=total_loss/counter=0.06082224680972194\n",
      "confusion_matrix=\n",
      "[[  0   6  87]\n",
      " [  0  39 176]\n",
      " [  0   2 196]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 93},\n",
      " '1': {'f1-score': 0.29770992366412213,\n",
      "       'precision': 0.8297872340425532,\n",
      "       'recall': 0.1813953488372093,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.5966514459665144,\n",
      "       'precision': 0.42701525054466233,\n",
      "       'recall': 0.98989898989899,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.4644268774703557,\n",
      " 'macro avg': {'f1-score': 0.2981204565435455,\n",
      "               'precision': 0.4189341615290718,\n",
      "               'recall': 0.3904314462453997,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.35996960452402393,\n",
      "                  'precision': 0.5196705038082847,\n",
      "                  'recall': 0.4644268774703557,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "Mean of avg_training_losses=0.05316464556014444\n",
      "total_loss=20.991324931383133\n",
      "counter=506\n",
      "loss=total_loss/counter=0.04148483188020382\n",
      "confusion_matrix=\n",
      "[[  0  65  28]\n",
      " [  0 172  43]\n",
      " [  0   6 192]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 93},\n",
      " '1': {'f1-score': 0.7510917030567685,\n",
      "       'precision': 0.7078189300411523,\n",
      "       'recall': 0.8,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8329718004338394,\n",
      "       'precision': 0.7300380228136882,\n",
      "       'recall': 0.9696969696969697,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.7193675889328063,\n",
      " 'macro avg': {'f1-score': 0.5280211678302026,\n",
      "               'precision': 0.47928565095161346,\n",
      "               'recall': 0.5898989898989899,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.6450852423776787,\n",
      "                  'precision': 0.5864201550908261,\n",
      "                  'recall': 0.7193675889328063,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 2\n",
      "Mean of avg_training_losses=0.03935307299527596\n",
      "total_loss=22.003983214497566\n",
      "counter=506\n",
      "loss=total_loss/counter=0.043486132834975426\n",
      "confusion_matrix=\n",
      "[[ 41  14  38]\n",
      " [ 11 149  55]\n",
      " [  0   4 194]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.5655172413793104,\n",
      "       'precision': 0.7884615384615384,\n",
      "       'recall': 0.44086021505376344,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.7801047120418849,\n",
      "       'precision': 0.8922155688622755,\n",
      "       'recall': 0.6930232558139535,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8,\n",
      "       'precision': 0.6759581881533101,\n",
      "       'recall': 0.9797979797979798,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.758893280632411,\n",
      " 'macro avg': {'f1-score': 0.7152073178070651,\n",
      "               'precision': 0.7855450984923747,\n",
      "               'recall': 0.7045604835552323,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.7484498350539153,\n",
      "                  'precision': 0.7885236988866952,\n",
      "                  'recall': 0.758893280632411,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 3\n",
      "Mean of avg_training_losses=0.03365816892982703\n",
      "total_loss=12.470255836844444\n",
      "counter=506\n",
      "loss=total_loss/counter=0.0246447743811155\n",
      "confusion_matrix=\n",
      "[[ 75   8  10]\n",
      " [ 18 170  27]\n",
      " [  5   7 186]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7853403141361257,\n",
      "       'precision': 0.7653061224489796,\n",
      "       'recall': 0.8064516129032258,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.85,\n",
      "       'precision': 0.918918918918919,\n",
      "       'recall': 0.7906976744186046,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8836104513064134,\n",
      "       'precision': 0.8340807174887892,\n",
      "       'recall': 0.9393939393939394,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8517786561264822,\n",
      " 'macro avg': {'f1-score': 0.839650255147513,\n",
      "               'precision': 0.8394352529522292,\n",
      "               'recall': 0.8455144089052565,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8512678232674497,\n",
      "                  'precision': 0.8574881798776738,\n",
      "                  'recall': 0.8517786561264822,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 4\n",
      "Mean of avg_training_losses=0.027100309634977202\n",
      "total_loss=13.964034393429756\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027596905915869083\n",
      "confusion_matrix=\n",
      "[[ 68  13  12]\n",
      " [ 14 174  27]\n",
      " [  4   7 187]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7597765363128492,\n",
      "       'precision': 0.7906976744186046,\n",
      "       'recall': 0.7311827956989247,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8508557457212714,\n",
      "       'precision': 0.8969072164948454,\n",
      "       'recall': 0.8093023255813954,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8820754716981131,\n",
      "       'precision': 0.827433628318584,\n",
      "       'recall': 0.9444444444444444,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8478260869565217,\n",
      " 'macro avg': {'f1-score': 0.8309025845774113,\n",
      "               'precision': 0.8383461730773446,\n",
      "               'recall': 0.8283098552415882,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8463323055403058,\n",
      "                  'precision': 0.8502011732695685,\n",
      "                  'recall': 0.8478260869565217,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 5\n",
      "Mean of avg_training_losses=0.025597579679708545\n",
      "total_loss=12.878582388162613\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02545174385012374\n",
      "confusion_matrix=\n",
      "[[ 75  11   7]\n",
      " [ 15 176  24]\n",
      " [  6   9 183]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7936507936507936,\n",
      "       'precision': 0.78125,\n",
      "       'recall': 0.8064516129032258,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.856447688564477,\n",
      "       'precision': 0.8979591836734694,\n",
      "       'recall': 0.8186046511627907,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8883495145631068,\n",
      "       'precision': 0.8551401869158879,\n",
      "       'recall': 0.9242424242424242,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.857707509881423,\n",
      " 'macro avg': {'f1-score': 0.8461493322594592,\n",
      "               'precision': 0.8447831235297857,\n",
      "               'recall': 0.8497662294361469,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8573892899888962,\n",
      "                  'precision': 0.8597534219350625,\n",
      "                  'recall': 0.857707509881423,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 6\n",
      "Mean of avg_training_losses=0.02258527386845566\n",
      "total_loss=11.354405876249075\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02243953730484007\n",
      "confusion_matrix=\n",
      "[[ 81   9   3]\n",
      " [ 21 180  14]\n",
      " [  9  10 179]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7941176470588235,\n",
      "       'precision': 0.7297297297297297,\n",
      "       'recall': 0.8709677419354839,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8695652173913043,\n",
      "       'precision': 0.9045226130653267,\n",
      "       'recall': 0.8372093023255814,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9086294416243654,\n",
      "       'precision': 0.9132653061224489,\n",
      "       'recall': 0.9040404040404041,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8695652173913043,\n",
      " 'macro avg': {'f1-score': 0.8574374353581643,\n",
      "               'precision': 0.8491725496391686,\n",
      "               'recall': 0.8707391494338231,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8709843722474809,\n",
      "                  'precision': 0.8758177021465513,\n",
      "                  'recall': 0.8695652173913043,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 7\n",
      "Mean of avg_training_losses=0.019880209746220567\n",
      "total_loss=13.959329649806023\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027587608003569214\n",
      "confusion_matrix=\n",
      "[[ 75   8  10]\n",
      " [ 16 170  29]\n",
      " [  4   6 188]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7978723404255319,\n",
      "       'precision': 0.7894736842105263,\n",
      "       'recall': 0.8064516129032258,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8521303258145363,\n",
      "       'precision': 0.9239130434782609,\n",
      "       'recall': 0.7906976744186046,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.884705882352941,\n",
      "       'precision': 0.8281938325991189,\n",
      "       'recall': 0.9494949494949495,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8557312252964426,\n",
      " 'macro avg': {'f1-score': 0.8449028495310031,\n",
      "               'precision': 0.8471935200959688,\n",
      "               'recall': 0.8488814122722599,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8549049652481859,\n",
      "                  'precision': 0.8617484897905743,\n",
      "                  'recall': 0.8557312252964426,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 8\n",
      "Mean of avg_training_losses=0.019874068738628677\n",
      "total_loss=13.747260624542832\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027168499257989788\n",
      "confusion_matrix=\n",
      "[[ 72   9  12]\n",
      " [ 14 174  27]\n",
      " [  3   6 189]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7912087912087912,\n",
      "       'precision': 0.8089887640449438,\n",
      "       'recall': 0.7741935483870968,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8613861386138614,\n",
      "       'precision': 0.9206349206349206,\n",
      "       'recall': 0.8093023255813954,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8873239436619719,\n",
      "       'precision': 0.8289473684210527,\n",
      "       'recall': 0.9545454545454546,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8596837944664032,\n",
      " 'macro avg': {'f1-score': 0.8466396244948747,\n",
      "               'precision': 0.8528570177003058,\n",
      "               'recall': 0.8460137761713155,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8586375063823481,\n",
      "                  'precision': 0.8642372370356841,\n",
      "                  'recall': 0.8596837944664032,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n",
      "EPOCH 9\n",
      "Mean of avg_training_losses=0.017817516407863363\n",
      "total_loss=11.942470572888851\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02360172049978034\n",
      "confusion_matrix=\n",
      "[[ 79   8   6]\n",
      " [ 17 186  12]\n",
      " [  7  12 179]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8061224489795918,\n",
      "       'precision': 0.7669902912621359,\n",
      "       'recall': 0.8494623655913979,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8836104513064134,\n",
      "       'precision': 0.9029126213592233,\n",
      "       'recall': 0.8651162790697674,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9063291139240507,\n",
      "       'precision': 0.9086294416243654,\n",
      "       'recall': 0.9040404040404041,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8774703557312253,\n",
      " 'macro avg': {'f1-score': 0.8653540047366852,\n",
      "               'precision': 0.8595107847485749,\n",
      "               'recall': 0.8728730162338564,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8782584967251837,\n",
      "                  'precision': 0.8801678658522452,\n",
      "                  'recall': 0.8774703557312253,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 10\n",
      "Mean of avg_training_losses=0.015003236330766966\n",
      "total_loss=14.032218029722571\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027731656185222473\n",
      "confusion_matrix=\n",
      "[[ 78   8   7]\n",
      " [ 20 175  20]\n",
      " [  6   8 184]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.7918781725888324,\n",
      "       'precision': 0.75,\n",
      "       'recall': 0.8387096774193549,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8620689655172414,\n",
      "       'precision': 0.9162303664921466,\n",
      "       'recall': 0.813953488372093,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8997555012224939,\n",
      "       'precision': 0.8720379146919431,\n",
      "       'recall': 0.9292929292929293,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8636363636363636,\n",
      " 'macro avg': {'f1-score': 0.8512342131095226,\n",
      "               'precision': 0.8460894270613633,\n",
      "               'recall': 0.8606520316947924,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8639151914605181,\n",
      "                  'precision': 0.8683854464522061,\n",
      "                  'recall': 0.8636363636363636,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 11\n",
      "Mean of avg_training_losses=0.013587140818089833\n",
      "total_loss=13.336229261010885\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02635618431029819\n",
      "confusion_matrix=\n",
      "[[ 80   5   8]\n",
      " [ 21 174  20]\n",
      " [  4   7 187]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8080808080808081,\n",
      "       'precision': 0.7619047619047619,\n",
      "       'recall': 0.8602150537634409,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8678304239401496,\n",
      "       'precision': 0.9354838709677419,\n",
      "       'recall': 0.8093023255813954,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9055690072639224,\n",
      "       'precision': 0.8697674418604651,\n",
      "       'recall': 0.9444444444444444,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8715415019762845,\n",
      " 'macro avg': {'f1-score': 0.86049341309496,\n",
      "               'precision': 0.8557186915776563,\n",
      "               'recall': 0.8713206079297603,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8716160469108775,\n",
      "                  'precision': 0.8778658668054928,\n",
      "                  'recall': 0.8715415019762845,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 12\n",
      "Mean of avg_training_losses=0.012099968147918758\n",
      "total_loss=13.423819325864315\n",
      "counter=506\n",
      "loss=total_loss/counter=0.026529287205265446\n",
      "confusion_matrix=\n",
      "[[ 76   7  10]\n",
      " [ 13 180  22]\n",
      " [  3   6 189]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8216216216216217,\n",
      "       'precision': 0.8260869565217391,\n",
      "       'recall': 0.8172043010752689,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8823529411764707,\n",
      "       'precision': 0.9326424870466321,\n",
      "       'recall': 0.8372093023255814,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9021479713603817,\n",
      "       'precision': 0.8552036199095022,\n",
      "       'recall': 0.9545454545454546,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8794466403162056,\n",
      " 'macro avg': {'f1-score': 0.868707511386158,\n",
      "               'precision': 0.8713110211592912,\n",
      "               'recall': 0.869653019315435,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8789367420812403,\n",
      "                  'precision': 0.8827560047700179,\n",
      "                  'recall': 0.8794466403162056,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 13\n",
      "Mean of avg_training_losses=0.010971814703276952\n",
      "total_loss=12.26197505183518\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02423315227635411\n",
      "confusion_matrix=\n",
      "[[ 76   9   8]\n",
      " [ 13 187  15]\n",
      " [  4   8 186]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8172043010752688,\n",
      "       'precision': 0.8172043010752689,\n",
      "       'recall': 0.8172043010752689,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8926014319809069,\n",
      "       'precision': 0.9166666666666666,\n",
      "       'recall': 0.8697674418604651,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.914004914004914,\n",
      "       'precision': 0.8899521531100478,\n",
      "       'recall': 0.9393939393939394,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8873517786561265,\n",
      " 'macro avg': {'f1-score': 0.8746035490203633,\n",
      "               'precision': 0.8746077069506611,\n",
      "               'recall': 0.8754552274432245,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8871191321123874,\n",
      "                  'precision': 0.8879325289508355,\n",
      "                  'recall': 0.8873517786561265,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n",
      "Model saved successfully\n",
      "EPOCH 14\n",
      "Mean of avg_training_losses=0.011812235026136333\n",
      "total_loss=13.968811078928411\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027606346005787374\n",
      "confusion_matrix=\n",
      "[[ 79   5   9]\n",
      " [ 16 173  26]\n",
      " [  4   6 188]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8229166666666666,\n",
      "       'precision': 0.797979797979798,\n",
      "       'recall': 0.8494623655913979,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8671679197994988,\n",
      "       'precision': 0.9402173913043478,\n",
      "       'recall': 0.8046511627906977,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.8931116389548693,\n",
      "       'precision': 0.8430493273542601,\n",
      "       'recall': 0.9494949494949495,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8695652173913043,\n",
      " 'macro avg': {'f1-score': 0.8610654084736783,\n",
      "               'precision': 0.8604155055461353,\n",
      "               'recall': 0.8678694926256817,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8691866744465541,\n",
      "                  'precision': 0.8760526228432796,\n",
      "                  'recall': 0.8695652173913043,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 15\n",
      "Mean of avg_training_losses=0.01028549829232103\n",
      "total_loss=13.083655810914934\n",
      "counter=506\n",
      "loss=total_loss/counter=0.02585702729429829\n",
      "confusion_matrix=\n",
      "[[ 80   7   6]\n",
      " [ 19 183  13]\n",
      " [  5   9 184]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8121827411167513,\n",
      "       'precision': 0.7692307692307693,\n",
      "       'recall': 0.8602150537634409,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8840579710144927,\n",
      "       'precision': 0.9195979899497487,\n",
      "       'recall': 0.8511627906976744,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9177057356608479,\n",
      "       'precision': 0.9064039408866995,\n",
      "       'recall': 0.9292929292929293,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.883399209486166,\n",
      " 'macro avg': {'f1-score': 0.8713154825973639,\n",
      "               'precision': 0.8650775666890725,\n",
      "               'recall': 0.8802235912513483,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8840142180885804,\n",
      "                  'precision': 0.8867984380893755,\n",
      "                  'recall': 0.883399209486166,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 16\n",
      "Mean of avg_training_losses=0.008282903172570742\n",
      "total_loss=12.008555309846997\n",
      "counter=506\n",
      "loss=total_loss/counter=0.023732322746733196\n",
      "confusion_matrix=\n",
      "[[ 82   5   6]\n",
      " [ 18 189   8]\n",
      " [  4  11 183]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.83248730964467,\n",
      "       'precision': 0.7884615384615384,\n",
      "       'recall': 0.8817204301075269,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.9,\n",
      "       'precision': 0.9219512195121952,\n",
      "       'recall': 0.8790697674418605,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9265822784810126,\n",
      "       'precision': 0.9289340101522843,\n",
      "       'recall': 0.9242424242424242,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8972332015810277,\n",
      " 'macro avg': {'f1-score': 0.8863565293752275,\n",
      "               'precision': 0.8797822560420059,\n",
      "               'recall': 0.8950108739306039,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8979933022454443,\n",
      "                  'precision': 0.9001489511505876,\n",
      "                  'recall': 0.8972332015810277,\n",
      "                  'support': 506}}\n",
      "New max_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully\n",
      "EPOCH 17\n",
      "Mean of avg_training_losses=0.007870683767722816\n",
      "total_loss=14.225098312366754\n",
      "counter=506\n",
      "loss=total_loss/counter=0.0281128425145588\n",
      "confusion_matrix=\n",
      "[[ 76   9   8]\n",
      " [ 18 181  16]\n",
      " [  3   9 186]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8,\n",
      "       'precision': 0.7835051546391752,\n",
      "       'recall': 0.8172043010752689,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8743961352657005,\n",
      "       'precision': 0.9095477386934674,\n",
      "       'recall': 0.8418604651162791,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9117647058823529,\n",
      "       'precision': 0.8857142857142857,\n",
      "       'recall': 0.9393939393939394,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8754940711462451,\n",
      " 'macro avg': {'f1-score': 0.8620536137160179,\n",
      "               'precision': 0.8595890596823095,\n",
      "               'recall': 0.8661529018618291,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.875345021436426,\n",
      "                  'precision': 0.8770556754386706,\n",
      "                  'recall': 0.8754940711462451,\n",
      "                  'support': 506}}\n",
      "New max_weighted_f1\n",
      "Model saved successfully\n",
      "EPOCH 18\n",
      "Mean of avg_training_losses=0.0066660917678932246\n",
      "total_loss=13.8629724602215\n",
      "counter=506\n",
      "loss=total_loss/counter=0.027397178775141303\n",
      "confusion_matrix=\n",
      "[[ 74  11   8]\n",
      " [ 10 189  16]\n",
      " [  4   8 186]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8176795580110496,\n",
      "       'precision': 0.8409090909090909,\n",
      "       'recall': 0.7956989247311828,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8936170212765957,\n",
      "       'precision': 0.9086538461538461,\n",
      "       'recall': 0.8790697674418605,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9117647058823529,\n",
      "       'precision': 0.8857142857142857,\n",
      "       'recall': 0.9393939393939394,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.8873517786561265,\n",
      " 'macro avg': {'f1-score': 0.8743537617233327,\n",
      "               'precision': 0.8784257409257409,\n",
      "               'recall': 0.8713875438556609,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8867614036249044,\n",
      "                  'precision': 0.8872263852748042,\n",
      "                  'recall': 0.8873517786561265,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n",
      "EPOCH 19\n",
      "Mean of avg_training_losses=0.006214701821275906\n",
      "total_loss=15.929752147756517\n",
      "counter=506\n",
      "loss=total_loss/counter=0.03148172361216703\n",
      "confusion_matrix=\n",
      "[[ 80   5   8]\n",
      " [ 15 177  23]\n",
      " [  2   6 190]]\n",
      "classification_report=\n",
      "{'0': {'f1-score': 0.8421052631578948,\n",
      "       'precision': 0.8247422680412371,\n",
      "       'recall': 0.8602150537634409,\n",
      "       'support': 93},\n",
      " '1': {'f1-score': 0.8784119106699751,\n",
      "       'precision': 0.9414893617021277,\n",
      "       'recall': 0.8232558139534883,\n",
      "       'support': 215},\n",
      " '2': {'f1-score': 0.9069212410501193,\n",
      "       'precision': 0.8597285067873304,\n",
      "       'recall': 0.9595959595959596,\n",
      "       'support': 198},\n",
      " 'accuracy': 0.883399209486166,\n",
      " 'macro avg': {'f1-score': 0.8758128049593298,\n",
      "               'precision': 0.8753200455102318,\n",
      "               'recall': 0.8810222757709628,\n",
      "               'support': 506},\n",
      " 'weighted avg': {'f1-score': 0.8828947746949654,\n",
      "                  'precision': 0.8880385139084662,\n",
      "                  'recall': 0.883399209486166,\n",
      "                  'support': 506}}\n",
      "New max_macro_f1\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    avg_training_losses = list()\n",
    "    \n",
    "    for small_batch_no, small_batch in enumerate(train_dataloader):\n",
    "        input = small_batch[0].clone().detach().to(DEVICE)\n",
    "        target = small_batch[1].clone().detach().to(DEVICE)\n",
    "        avg_training_losses.append(\n",
    "            train_step(input, target, small_batch_no)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    total_loss, counter, confusion_matrix, classification_report = evaluate()\n",
    "    print(f'EPOCH {epoch}')\n",
    "    print(f'Mean of avg_training_losses={np.mean(avg_training_losses)}')\n",
    "    print(f'total_loss={total_loss}')\n",
    "    print(f'counter={counter}')\n",
    "    print(f'loss=total_loss/counter={total_loss/counter}')\n",
    "    print(f'confusion_matrix=\\n{confusion_matrix}')\n",
    "    print('classification_report=')\n",
    "    pprint.pprint(classification_report)\n",
    "    \n",
    "    save_log(\n",
    "        epoch,\n",
    "        avg_training_losses=avg_training_losses,\n",
    "        total_loss=total_loss,\n",
    "        counter=counter,\n",
    "        loss=total_loss/counter,\n",
    "        confusion_matrix=confusion_matrix,\n",
    "        classification_report=classification_report\n",
    "    )\n",
    "    \n",
    "    if classification_report['accuracy'] > max_accuracy:\n",
    "        print(f'New max_accuracy')\n",
    "        max_accuracy = classification_report['accuracy']\n",
    "        max_accuracy_index = epoch\n",
    "        save_model('max_accuracy')\n",
    "        \n",
    "    elif classification_report['macro avg']['f1-score'] > max_macro_f1:\n",
    "        print(f'New max_macro_f1')\n",
    "        max_macro_f1 = classification_report['macro avg']['f1-score']\n",
    "        max_macro_f1_index = epoch\n",
    "        save_model('max_macro_f1')\n",
    "    \n",
    "    elif classification_report['weighted avg']['f1-score'] > max_weighted_f1:\n",
    "        print(f'New max_weighted_f1')\n",
    "        max_weighted_f1 = classification_report['weighted avg']['f1-score']\n",
    "        max_weighted_f1_index = epoch\n",
    "        save_model('max_weighted_f1')\n",
    "    \n",
    "    elif epoch == num_epochs - 1:\n",
    "        save_model(f'{epoch}_last')\n",
    "    \n",
    "    elif epoch % 40 == 0:\n",
    "        save_model(f'{epoch}_checkpoint')\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "save_log(\n",
    "    'post_train_info',\n",
    "    max_accuracy=max_accuracy,\n",
    "    max_accuracy_index=max_accuracy_index,\n",
    "    max_macro_f1=max_macro_f1,\n",
    "    max_macro_f1_index=max_macro_f1_index,\n",
    "    max_weighted_f1=max_weighted_f1,\n",
    "    max_weighted_f1_index=max_weighted_f1_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972332015810277"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_accuracy\n",
    "# max_accuracy_index\n",
    "# max_macro_f1\n",
    "# max_macro_f1_index\n",
    "# max_weighted_f1\n",
    "# max_weighted_f1_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Maximum recorded accuracy = 89.7%*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    num_classes = 3\n",
    "    input_dim = 768\n",
    "\n",
    "    classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n",
    "    model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\n",
    "    \n",
    "    DEMO_MODEL_PATH = 'model_max_weighted_f1.pth'\n",
    "    model.load_state_dict(torch.load(DEMO_MODEL_PATH))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    print(f'Loaded model to [{DEVICE}] in [{DEMO_MODEL_PATH}]')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_transform():\n",
    "    text_transform = torchtext.models.XLMR_LARGE_ENCODER.transform()\n",
    "    return text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model, text_transform, label_map):\n",
    "    transformed_text = text_transform(sentence)\n",
    "    out = model(torch.tensor([transformed_text]).to(DEVICE))\n",
    "    return label_map[torch.argmax(out).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0.0: 'negative',\n",
    "    1.0: 'neutral',\n",
    "    2.0: 'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model to [cpu] in [model_max_weighted_f1.pth]\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model()\n",
    "text_transform = prepare_text_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'Terrible!'\n",
    "predict(sample_text, model, text_transform, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
